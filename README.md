# StudyDeepLearning

## 1일차
- 강화학습 용어 정리(간략하게)
    - 보상
    - 학습전략, 사이클
    - 에피소드
    - 마르코프 결정 과정
    - 정책계산법
        - 정책반복법
        - 가치반복법
            - Saras(살사)
            - Q-Learning(큐러닝)
            - DQN(딥마인드에서 제작, 딥러닝)
- 다중 슬롯머신 구현

## 2일차
- 클래스의 개념, 구성, 문법
- 게임엔진(EpsilonGreedyEngine, UCB1Engine)
- 시뮬레이션(슬롯머신)
- 간단한 미로게임 만들기
    - 게임 맵 그리고 미로 만들기(plot 사용)

## 3일차
- 요소 실행
    - 에이전트 상태 정의, 시뮬레이션
    - 최단거리로 이동하게 만들기
- 정책 갱신함수
- 가치 계산법

- 수익
    - 즉시 보상을 제외한 미래에서 얻을 수 있는 수익은 확정되지 않는 값이다
    - 에이전트는 조건부로 정책을 고정하여 미래의 수입을 계산할 수 있다
        - 이렇게 반영된 수익을 가치라고 부른다
        - 이런 가치를 가장 크게 얻을 수 있는 조건을 찾아내는 것 => 학습목표

- 구현하기 위한 방법
    - 행동 가치 함수
        - Q 함수
        - Sarsa, Q-Learning, DQN,...
    - 상태 가치 함수
        - V 함수
        - A2C, Dueling Network
- 벨만 방정식
    - 행동 가치 함수, 상태 가치 함수를 수학적으로 표현한 것
    - 현재 상태와 다음 상태의 관계를 나타내는 방정식
- 마르크프 계산결정
    - 벨만 방정식이 성립하기 위한 환경은 MDP이여야 한다 -> 다음 상태가 현재 상태에서 선택한 행동에 따라 확정되는 시스템
- Q-Learning & Sarsa

