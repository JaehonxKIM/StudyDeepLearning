# -*- coding: utf-8 -*-
"""6.파이토치(PyTorch)기초.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/198aLrHcuSWwjN9fGs5vp82URya29PjhC

# 개요

- Define by Run
  - 매 단게를 바로 확인 가능한 장점이 있다
  - 연구기관 등에서 많이 사용한다(R&D)
  - 디버깅 용이, 파이썬 작성 스타일과 유사
  - 객체지향적, 절차적, 함수지향적 모두 가능, 객체 지향적 코드를 많이 사용한다
"""

import torch

# 1.11.0 버전, 쿠다 113 지원
torch.__version__

from IPython.core.display import Image
Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/tensor_style.jpeg')
# 텐서

"""# 텐서 생성

- 리스트, 배열(array)로부터 만들수 있다
"""

list_src = [
  [1,2,3],
  [11,12,13]
]
list_src

# 구동 즉시 텐서가 생성되고 데이터가 세팅된다
# 바로 확인 가능하다 -> 디버깅이 용이, 각 단계를 체크할 수 있다
x = torch.Tensor(list_src)
x

import numpy as np

arr = np.array(list_src)
arr

# 배열로부터 텐서 생성
x = torch.Tensor(arr)
x

# 텐서로부터 배열로
x.numpy()

# 난수를 원소로 가진 텐서 
# 0 <= 원소 < 5
torch.randint(0, 5, size = (2,3))

# 영행렬
torch.zeros(2,2)

# 구성원이 모두 1인 행렬
torch.ones(2,2)

# 텐서 x에 shape을 본따서 영행렬 생성
torch.zeros_like(x)

"""# GPU 사용

- 텐서별로 gpu를 지정할 수 있다
- 단위별로 적용이 가능하나, 연계된 텐서들은 한가지 방식으로 학습해야 연동된다
"""

# 엔비디아 GPU가 지원되는가?
torch.cuda.is_available()

DEVICE = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )
DEVICE

# 특정 텐서에 적용
x.to(DEVICE)

# 장비 개수 체크
torch.cuda.device_count()

"""# 텐서 타입"""

Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/torch2.png')
# 데이터는 모두 수치로 표현해야 한다(타입이 수치만 존재한다)

a = torch.FloatTensor(np.array([1,2,3,4]))
a

# 텐서 기본 속성 확인
a, type(a), a.type(), a.shape , a.dtype

"""# 텐서의 조작 및 연산

- 텐서를 만나면 바로 체크할 내용
  - 모양 : size(), shape
  - 차원 : dim() , ndim
  - 타입 : type(), dtype, 텐서.type()
"""

# 토치의 난수 고정
torch.manual_seed(1024)

# 텐서가 생성되면 바로 체크할 포인트
x = torch.randint(1, 10, size = (2,3,4))
x

x.type(), x.dim(), x.size()

"""## indexing, slicing

- 텐서에서 특정 데이터를 추출한다
  - 인덱싱 : 차원축소가 진행된다
  - 슬라이싱 : 차원 유지
"""

x

# 인덱싱 -> 차원 축소됨
x[0], x[0].size(), x[0][0], x[0][0][0]

# Commented out IPython magic to ensure Python compatibility.
# 텐서 시각화
import matplotlib.pyplot as plt
# %matplotlib inline

def draw3DTensor(src) :
  fig, axes = plt.subplots(len(src), 1) # 2,1
  for i in range(len(src)) :
    # 2차원 텐서를 시각화
    axes[i].matshow(src[i].numpy(), vmin = 0, vmax = 1, cmap = 'gray')
  plt.show()
  pass

onesTensor = torch.ones_like(x)
draw3DTensor(onesTensor)

onesTensor = torch.zeros_like(x)
draw3DTensor(onesTensor)

onesTensor[0, 1, 2] = 0
draw3DTensor( onesTensor )

onesTensor

onesTensor[1, :2, 1:3,] = 0
draw3DTensor(onesTensor)

"""## view

- numpy의 reshape과 동일기능
- 변경전후 원소수 동일
- 원소의 순서도 동일
"""

x, x.shape, x.size()

x.reshape( 2,2,6 )

# 텐서에서 추천하는 코드
x.view(2, 2, 6)

x.view(-1, 12)

"""## transpose

- 차원 맞교환
"""

# 대표적인 축교환
x.T.size(), x.T

# 특정 차원간의 맞교환
x.transpose( 0, 1 ), x.transpose( 0, 1 ).size()

"""## sqeeze, unsqeeze

- sqeeze : 차원 값이 1인 차원 제거 
- unsqeeze : 차원 값이 1인 차원을 추가
"""

x = torch.rand((3, 1, 2, 4, 1))
x

tmp  = x.squeeze()
tmp.size(), tmp

# [3,2,4] =>
# 특정 자리에 1차원을 추가한다 -> 차원증가
x.squeeze().unsqueeze(2).size()

"""## cat, stack

- 텐서를 합친다
- cat
  - 단순 합치기
- stack
  - 쌓는다(쌓아서 합침)
"""

x.dim(), x.size(), x.ndimension()

a = torch.rand((2, 3))
a

b = torch.rand((2, 3))
b

# 단순 합치기
tmp = torch.cat([a,b], dim = 0)
tmp.size(), tmp

tmp = torch.cat([a,b], dim = 1)
tmp.size(), tmp

# 쌓는다 -> 그릇을 하나 준비하고 차례대로 쌓는다
tmp = torch.stack([a,a, b], dim = 0)
tmp.size(), tmp

# 잘 사용하지 않는 그냥 실습상 구조
#tmp = torch.stack([a,a, b], dim = 1)
tmp = torch.stack([a,b], dim = 1)
tmp.size(), tmp

"""## 기초연산

- + , -, *, /
- 브로드케스팅
"""

x = torch.Tensor([[1, 2, 3],[4, 5, 6]])
y = torch.Tensor([[10, 20, 30],[40, 50, 60]])
x, y, x.size()

# 텐서의 합 -> 각 원소 자리에 있는 값들까지 연산수행
x + y, x - y, x * y, x / y

# 1차원 텐서
z = torch.Tensor([10])
z.size(), z

# (2,3) + (1,)
x + y
# 브로드캐스팅에 의해서 연산에 필요한 만큼 z 텐서를 stretch 하여 연산을 수행하였다

Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/broadcasting_1.png')

Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/broadcasting_2.png')

Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/broadcasting_3.png')

Image('/content/drive/MyDrive/ComputerProgramming/DeepLearning/2.딥러닝/dl/broadcasting_4.png')

x + y, torch.add( x, y ), torch.sub( x, y )

torch.mul( x, y ), torch.div( x, y )

"""# 텐서의 기타 함수"""

x = torch.Tensor([1, 2, 3])
y = torch.Tensor([4, 5, 6])
x, y, x.size()

# 내적
# 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 14 + 18 = 32
torch.dot(x, y)

x = torch.Tensor(
    [
     [1,3],
     [2,3],
     [5,6],
    ]
)
x.size()

y = torch.Tensor(
    [
     [7,8],
     [9,10],
    ]
)
y.size()

print(x) 
print(y)

# 행렬의 곱, xW
# (3,2) * (2,2) => (3,2)
# 34 = 1*7 + 3*9 = 7 + 27 = 34
tmp = torch.mm(x,y)
tmp.size(), tmp