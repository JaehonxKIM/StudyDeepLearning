# -*- coding: utf-8 -*-
"""3. 강화학습_정책계산법_정책경사법_sarsa_Q-Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oXZfhxtLUJSd4QsBmOcHc1VtBAfNKRn5

# 개요

- Policy를 갱신하는 기법(정책 계산 방법)
  - 정책 반복법
    - 행동을 중시
    - 행동을 기반으로 정책을 갱신 => 행동을 유도
    - **정책 경사법**
  - 가치 반복법
    - 가치를 중시
    - 가치 계산이 핵심 -> 가치를 많이 주는 방향으로 정책이 경신
    - Sarsa, Q-Learning, DQN...

# 미로게임

- 보드게임
- 게임판 : 3 x 3, 정사각형
- 특징
  - 입구와 출구가 각각 1개만 존재
  - 막힌 사각형의 격자형 간에 이동할 수 있는 방향이 존재
  - 에이전트(마우스) 4방향으로 이동 가능
  - 액션 : 상(0), 우(1), 하(2), 좌(3)
  - 게임뷰는 탑 뷰
  - 1 step에 한 칸씩 이동
- 목적
  - **에이전트는 미로게임판에서 최단거리로 입구에서 출발하여 출구로 나간다**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt

# %matplotlib inline

"""# 게임 맵 그리기"""

# 맵의 전체 크기
fig = plt.figure(figsize = (3,3))
# 외곽 벽 그리기
# 수평선 2개
plt.plot([0, 3],[3, 3], color = 'k') # 위 수평선
plt.plot([3, 0],[0, 0], color = 'k') # 아래 수평선
plt.plot([0, 0],[0, 2], color = 'k') # 왼쪽 수직선
plt.plot([3, 3],[1, 3], color = 'k') # 오른쪽 수직선

# 내부 미로
plt.plot([1, 1],[1, 2], color = 'k') 
plt.plot([2, 3],[2, 2], color = 'k') 
plt.plot([1, 2],[1, 1], color = 'k') 
plt.plot([2, 2],[0, 1], color = 'k')

# 각 포인트 위치 정보 표시 -> 상태
# 0,1,2 ~ 8 까지 위치 정보 표시
for x in range(3) :
  for y in range(3) :
    plt.text(x + 0.5, 3 - y - 0.5, str(x + 3 * y) , size = 20, ha = 'center', va = 'center')

# 에이전트 표시 -> 시작위치 0번에 위치
mouse = plt.plot(0 + 0.5, 3 - 0 - 0.5, marker = 'o', markersize = 25, color = 'r')

# 눈금 정리
plt.tick_params(bottom = False, left = False,
                labelbottom = False, labelleft = False)

# 차트 박스 제거 
plt.box(False)

# 출력
plt.show()